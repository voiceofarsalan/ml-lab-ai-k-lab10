{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fbf9a93",
   "metadata": {},
   "source": [
    "### MY DETAILS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8493908d",
   "metadata": {},
   "source": [
    "Name: Arsalan Ahmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6002e28d",
   "metadata": {},
   "source": [
    "Roll Number: 21I-0271"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df6b2c1",
   "metadata": {},
   "source": [
    "### IMPORTANT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb9103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1cf58f",
   "metadata": {},
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c22cf8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Balls:  15\n",
      "P(Reds):  0.3333333333333333\n",
      "P(Box1):  0.5\n",
      "P(Box1|Red) 0.4\n",
      "P(Red|Box1) 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "#PRINT ALL THE OUTPUTS \n",
    "P_Box1=0.5\n",
    "P_Box2=0.5\n",
    "Box1=[\"R\",\"R\",\"W\",\"W\",\"W\",\"W\",\"W\"]\n",
    "Box2=[\"R\",\"R\",\"R\",\"W\",\"W\",\"W\",\"W\",\"W\"]\n",
    "TotalRed=5\n",
    "TotalWhite=10\n",
    "TotalBalls=len(Box1)+len(Box2)\n",
    "print(\"Total Balls: \",TotalBalls)\n",
    "\n",
    "# P(Reds)\n",
    "P_Reds= TotalRed/TotalBalls\n",
    "print(\"P(Reds): \",P_Reds)\n",
    "\n",
    "# P(Box1)\n",
    "print(\"P(Box1): \",P_Box1)\n",
    "\n",
    "# P(Box1|Red)\n",
    "Red_Box1=0\n",
    "for x in Box1:\n",
    "    if x==\"R\":\n",
    "        Red_Box1+=1\n",
    "P_Box1Red= Red_Box1/TotalRed\n",
    "print(\"P(Box1|Red)\",P_Box1Red)\n",
    "\n",
    "# P(RED|Box1)\n",
    "P_RedBox1=(P_Box1Red*P_Reds)/P_Box1\n",
    "print(\"P(Red|Box1)\",P_RedBox1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1d65c",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c85e346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.]])\n",
      "tensor([[3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.]])\n",
      "After 0 epochs the loss is 14.558199882507324\n",
      "After 1 epochs the loss is 2.1123909950256348\n",
      "After 2 epochs the loss is 0.2975841462612152\n",
      "After 3 epochs the loss is 0.18503053486347198\n",
      "After 4 epochs the loss is 0.09406150132417679\n",
      "After 5 epochs the loss is 0.06855446845293045\n",
      "After 6 epochs the loss is 0.053668733686208725\n",
      "After 7 epochs the loss is 0.04762806370854378\n",
      "After 8 epochs the loss is 0.04414160177111626\n",
      "After 9 epochs the loss is 0.042101819068193436\n",
      "After 10 epochs the loss is 0.0406019389629364\n",
      "After 11 epochs the loss is 0.03937486186623573\n",
      "After 12 epochs the loss is 0.03827284649014473\n",
      "After 13 epochs the loss is 0.03724181652069092\n",
      "After 14 epochs the loss is 0.03625579923391342\n",
      "After 15 epochs the loss is 0.035303905606269836\n",
      "After 16 epochs the loss is 0.03438114747405052\n",
      "After 17 epochs the loss is 0.03348487243056297\n",
      "After 18 epochs the loss is 0.032613638788461685\n",
      "After 19 epochs the loss is 0.03176623955368996\n",
      "After 20 epochs the loss is 0.03094211034476757\n",
      "After 21 epochs the loss is 0.030140375718474388\n",
      "After 22 epochs the loss is 0.029360363259911537\n",
      "After 23 epochs the loss is 0.02860140986740589\n",
      "After 24 epochs the loss is 0.02786300890147686\n",
      "After 25 epochs the loss is 0.027144556865096092\n",
      "After 26 epochs the loss is 0.026445375755429268\n",
      "After 27 epochs the loss is 0.025765081867575645\n",
      "After 28 epochs the loss is 0.025102993473410606\n",
      "After 29 epochs the loss is 0.02445865608751774\n",
      "After 30 epochs the loss is 0.02383151464164257\n",
      "After 31 epochs the loss is 0.02322106994688511\n",
      "After 32 epochs the loss is 0.02262704260647297\n",
      "After 33 epochs the loss is 0.02204877883195877\n",
      "After 34 epochs the loss is 0.021485833451151848\n",
      "After 35 epochs the loss is 0.020937884226441383\n",
      "After 36 epochs the loss is 0.020404446870088577\n",
      "After 37 epochs the loss is 0.01988513395190239\n",
      "After 38 epochs the loss is 0.01937953196465969\n",
      "After 39 epochs the loss is 0.018887251615524292\n",
      "After 40 epochs the loss is 0.01840793527662754\n",
      "After 41 epochs the loss is 0.01794125698506832\n",
      "After 42 epochs the loss is 0.01748681627213955\n",
      "After 43 epochs the loss is 0.017044363543391228\n",
      "After 44 epochs the loss is 0.016613440588116646\n",
      "After 45 epochs the loss is 0.01619383506476879\n",
      "After 46 epochs the loss is 0.015785176306962967\n",
      "After 47 epochs the loss is 0.015387182123959064\n",
      "After 48 epochs the loss is 0.014999584294855595\n",
      "After 49 epochs the loss is 0.014622059650719166\n",
      "After 50 epochs the loss is 0.014254361391067505\n",
      "After 51 epochs the loss is 0.013896220363676548\n",
      "After 52 epochs the loss is 0.013547309674322605\n",
      "After 53 epochs the loss is 0.013207496143877506\n",
      "After 54 epochs the loss is 0.012876469641923904\n",
      "After 55 epochs the loss is 0.012554005719721317\n",
      "After 56 epochs the loss is 0.012239829637110233\n",
      "After 57 epochs the loss is 0.011933798901736736\n",
      "After 58 epochs the loss is 0.011635617353022099\n",
      "After 59 epochs the loss is 0.011345133185386658\n",
      "After 60 epochs the loss is 0.011062110774219036\n",
      "After 61 epochs the loss is 0.010786355473101139\n",
      "After 62 epochs the loss is 0.01051765400916338\n",
      "After 63 epochs the loss is 0.010255856439471245\n",
      "After 64 epochs the loss is 0.010000744834542274\n",
      "After 65 epochs the loss is 0.009752154350280762\n",
      "After 66 epochs the loss is 0.009509927593171597\n",
      "After 67 epochs the loss is 0.009273866191506386\n",
      "After 68 epochs the loss is 0.009043828584253788\n",
      "After 69 epochs the loss is 0.008819635026156902\n",
      "After 70 epochs the loss is 0.008601170964539051\n",
      "After 71 epochs the loss is 0.008388226851820946\n",
      "After 72 epochs the loss is 0.008180725388228893\n",
      "After 73 epochs the loss is 0.00797844585031271\n",
      "After 74 epochs the loss is 0.0077813174575567245\n",
      "After 75 epochs the loss is 0.007589189801365137\n",
      "After 76 epochs the loss is 0.007401915732771158\n",
      "After 77 epochs the loss is 0.007219336926937103\n",
      "After 78 epochs the loss is 0.007041417062282562\n",
      "After 79 epochs the loss is 0.006867945194244385\n",
      "After 80 epochs the loss is 0.00669887475669384\n",
      "After 81 epochs the loss is 0.006534065585583448\n",
      "After 82 epochs the loss is 0.006373350974172354\n",
      "After 83 epochs the loss is 0.006216756533831358\n",
      "After 84 epochs the loss is 0.006064053159207106\n",
      "After 85 epochs the loss is 0.005915167275816202\n",
      "After 86 epochs the loss is 0.005770039279013872\n",
      "After 87 epochs the loss is 0.005628542508929968\n",
      "After 88 epochs the loss is 0.005490580108016729\n",
      "After 89 epochs the loss is 0.0053560975939035416\n",
      "After 90 epochs the loss is 0.005224933382123709\n",
      "After 91 epochs the loss is 0.0050970581360161304\n",
      "After 92 epochs the loss is 0.004972401075065136\n",
      "After 93 epochs the loss is 0.004850856028497219\n",
      "After 94 epochs the loss is 0.004732313100248575\n",
      "After 95 epochs the loss is 0.004616742953658104\n",
      "After 96 epochs the loss is 0.004504023119807243\n",
      "After 97 epochs the loss is 0.0043941703625023365\n",
      "After 98 epochs the loss is 0.0042869881726801395\n",
      "After 99 epochs the loss is 0.004182474222034216\n",
      "At tensor tensor([200.]), the predicted value is, tensor([208.7757], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#APPLY NECESSARY ML CONCEPTS THAT MAY BE USEFUL\n",
    "x=torch.tensor([1,2,3,4,5,6],dtype=torch.float32).view(-1,1)\n",
    "y=x+2 #THE LINEAR RELATIONSHIP\n",
    "print(x)\n",
    "print(y)\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(1,1)\n",
    "        self.linear2=nn.Linear(1,1)\n",
    "        self.act_fn=nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        output1=self.linear(x)\n",
    "        out=self.act_fn(output1)\n",
    "        output2=self.linear(out)\n",
    "        return output2\n",
    "model=LinearModel()\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.01)\n",
    "epochs=100\n",
    "for i in range (epochs):\n",
    "    output=model(x)\n",
    "    loss=criterion(output,y)\n",
    "    print(f\"After {i} epochs the loss is {loss}\")\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "model.eval()\n",
    "test=torch.tensor([200],dtype=torch.float32)\n",
    "pred=model(test)\n",
    "print(f\"At tensor {test}, the predicted value is, {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5099de38",
   "metadata": {},
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "771f5b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.9715]], requires_grad=True)\n",
      "tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.8610], requires_grad=True)\n",
      "tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[0.4160]], requires_grad=True)\n",
      "tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.4552], requires_grad=True)\n",
      "tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 0 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 1 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 2 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 3 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 4 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 5 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 6 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 7 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 8 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 9 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 10 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 11 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 12 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 13 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 14 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 15 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 16 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 17 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 18 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 19 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 20 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 21 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 22 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 23 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 24 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 25 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 26 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 27 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 28 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 29 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 30 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 31 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 32 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 33 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 34 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 35 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 36 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 37 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 38 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 39 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 40 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 41 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 42 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 43 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 44 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 45 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 46 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 47 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 48 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 49 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 50 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 51 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 52 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 53 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 54 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 55 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 56 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 57 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 58 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 59 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 60 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 61 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 62 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 63 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 64 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 65 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 66 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 67 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 68 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 69 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 70 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 71 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 72 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 73 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 74 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 75 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 76 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 77 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 78 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 79 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 80 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 81 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 82 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 83 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 84 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 85 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 86 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 87 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 88 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 89 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 90 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 91 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 92 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 93 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 94 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 95 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 96 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 97 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 98 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 99 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.9437, grad_fn=<SumBackward0>)\n",
      "After 0 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 1 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 2 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 3 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 4 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 5 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 6 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 7 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 8 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 9 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 10 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 11 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 12 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 13 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 14 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 15 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 16 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 17 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 18 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 19 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 20 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 21 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 22 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 23 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 24 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 25 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 26 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 27 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 28 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 29 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 30 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 31 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 32 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 33 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 34 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 35 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 36 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 37 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 38 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 39 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 40 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 41 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 42 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 43 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 44 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 45 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 46 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 47 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 48 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 49 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 50 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 51 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 52 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 53 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 54 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 55 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 56 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 57 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 58 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 59 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 60 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 61 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 62 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 63 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 64 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 65 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 66 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 67 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 68 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 69 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 70 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 71 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 72 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 73 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 74 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 75 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 76 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 77 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 78 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 79 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 80 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 81 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 82 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 83 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 84 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 85 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 86 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 87 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 88 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 89 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 90 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 91 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 92 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 93 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 94 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 95 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 96 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 97 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 98 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 99 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.7413, grad_fn=<SumBackward0>)\n",
      "After 0 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 1 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 2 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 3 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 4 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 5 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 6 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 7 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 8 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 9 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 10 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 11 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 12 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 13 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 14 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 15 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 16 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 17 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 18 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 19 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 20 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 21 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 22 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 23 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 24 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 25 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 26 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 27 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 28 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 29 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 30 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 31 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 32 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 33 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 34 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 35 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 36 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 37 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 38 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 39 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 40 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 41 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 42 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 43 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 44 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 45 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 46 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 47 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 48 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 49 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 50 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 51 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 52 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 53 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 54 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 55 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 56 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 57 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 58 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 59 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 60 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 61 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 62 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 63 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 64 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 65 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 66 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 67 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 68 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 69 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 70 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 71 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 72 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 73 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 74 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 75 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 76 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 77 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 78 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 79 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 80 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 81 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 82 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 83 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 84 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 85 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 86 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 87 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 88 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 89 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 90 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 91 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 92 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 93 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 94 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 95 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 96 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 97 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 98 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 99 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.1731, grad_fn=<SumBackward0>)\n",
      "After 0 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 1 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 2 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 3 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 4 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 5 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 6 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 7 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 8 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 9 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 10 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 11 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 12 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 13 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 14 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 15 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 16 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 17 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 18 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 19 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 20 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 21 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 22 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 23 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 24 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 25 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 26 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 27 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 28 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 29 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 30 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 31 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 32 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 33 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 34 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 35 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 36 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 37 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 38 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 39 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 40 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 41 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 42 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 43 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 44 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 45 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 46 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 47 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 48 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 49 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 50 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 51 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 52 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 53 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 54 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 55 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 56 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 57 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 58 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 59 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 60 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 61 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 62 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 63 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 64 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 65 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 66 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 67 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 68 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 69 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 70 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 71 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 72 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 73 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 74 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 75 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 76 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 77 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 78 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 79 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 80 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 81 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 82 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 83 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 84 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 85 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 86 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 87 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 88 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 89 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 90 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 91 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 92 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 93 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 94 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 95 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 96 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 97 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 98 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n",
      "After 99 epochs the loss is 24.437353134155273\n",
      "Optimization tensor(0.2072, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#LOOP HERE\n",
    "model=LinearModel()\n",
    "criterion=nn.MSELoss()\n",
    "pro=[]\n",
    "for p in model.parameters():\n",
    "    print(p)\n",
    "    print(p.pow(2.0).sum())\n",
    "    pro.append(p.pow(2.0).sum())\n",
    "optimizer=optim.SGD(pro,lr=0.01)\n",
    "epochs=100\n",
    "for p in model.parameters():\n",
    "    p=p.pow(2.0).sum()\n",
    "    for i in range (epochs):\n",
    "        output=model(x)\n",
    "        loss=criterion(output,y)\n",
    "        print(f\"After {i} epochs the loss is {loss}\")\n",
    "        print(\"Optimization\",p)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa9f4a",
   "metadata": {},
   "source": [
    "Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d31ab",
   "metadata": {},
   "source": [
    "### WRITE HERE\n",
    "\n",
    "Loss.backward()= This is used to calculate the loss and learn in backward propagation of the model.It also computes the gradient of current tensor wrt graph leaves.\n",
    "\n",
    "\n",
    "optimizer.zero_grad()= This is a widely used gradient descent optimizing technique where gradient is set to zero to optimize the model. It resets the gradients of all optimized class tensors to zero or none.\n",
    "\n",
    "\n",
    "optimizer.step()= Performs a single optimization step.\n",
    "\n",
    "\n",
    "The following done in order will work in a way that loss.backward will compute the losses and the gradient of a current tensor, then optimizer.zero_grad will reset this gradient and the optimizer.step will move a single optimization step and move on to the next parameter, tensor and set of values. The problem with this is that the zero_grad after loss.backward will always reset the gradient therefore there will be no learning or change in loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "587cdb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Thanks alot for teaching us sir, proud to be your student as I learned alot from you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
